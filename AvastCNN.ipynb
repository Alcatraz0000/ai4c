{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlGV0rEgnrLD"
      },
      "source": [
        "### Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iV0RX8Gnwsy"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uXTt3stl4a33"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import gzip\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from collections import deque\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary #network summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import deque\n",
        "from collections import OrderedDict\n",
        "import multiprocessing\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uXEDH4tAry2"
      },
      "source": [
        "## DataSet Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GsZjUl-m2U6K"
      },
      "outputs": [],
      "source": [
        "class BinaryDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Loader for binary files. \n",
        "    \n",
        "    If you use the sort_by_file_size option, the dataset will store files from smallest to largest. This is meant to used with RandomChunkSampler to sammple batches of similarly sized files to maximize performance. \n",
        "    \n",
        "    TODO: Auto un-gzip files if they have g-zip compression \n",
        "    \"\"\"\n",
        "    def __init__(self, good_dir, bad_dir, sort_by_size=False, max_len=4000000):\n",
        "        \n",
        "        #Tuple (file_path, label, file_size)\n",
        "        self.all_files = []\n",
        "        self.max_len = max_len\n",
        "        \n",
        "        for roor_dir, dirs, files in os.walk(good_dir):\n",
        "            for file in files:\n",
        "                to_add = os.path.join(roor_dir,file)\n",
        "                self.all_files.append(  (to_add, 0, os.path.getsize(to_add))  )\n",
        "                \n",
        "        for roor_dir, dirs, files in os.walk(bad_dir):\n",
        "            for file in files:\n",
        "                to_add = os.path.join(roor_dir,file)\n",
        "                self.all_files.append(   (to_add, 1, os.path.getsize(to_add))  )\n",
        "                \n",
        "        if sort_by_size:\n",
        "            self.all_files.sort(key=lambda filename: filename[2])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        to_load, y, _ = self.all_files[index]\n",
        "        \n",
        "        try:\n",
        "            with gzip.open(to_load, 'rb') as f:\n",
        "                x = f.read(self.max_len)\n",
        "                #Need to use frombuffer b/c its a byte array, otherwise np.asarray will get wonked on trying to convert to ints\n",
        "                #So decode as uint8 (1 byte per value), and then convert\n",
        "                x = np.frombuffer(x, dtype=np.uint8).astype(np.int16)+1 #index 0 will be special padding index\n",
        "        except OSError:\n",
        "            #OK, you are not a gziped file. Just read in raw bytes from disk. \n",
        "            with open(to_load, 'rb') as f:\n",
        "                x = f.read(self.max_len)\n",
        "                #Need to use frombuffer b/c its a byte array, otherwise np.asarray will get wonked on trying to convert to ints\n",
        "                #So decode as uint8 (1 byte per value), and then convert\n",
        "                x = np.frombuffer(x, dtype=np.uint8).astype(np.int16)+1 #index 0 will be special padding index\n",
        "            \n",
        "        #x = np.pad(x, self.max_len-x.shape[0], 'constant')    \n",
        "        x = torch.tensor(x)\n",
        "\n",
        "        return x, torch.tensor([y])\n",
        "    \n",
        "class RandomChunkSampler(torch.utils.data.sampler.Sampler):\n",
        "    \"\"\"\n",
        "    Samples random \"chunks\" of a dataset, so that items within a chunk are always loaded together. Useful to keep chunks in similar size groups to reduce runtime. \n",
        "    \"\"\"\n",
        "    def __init__(self, data_source, batch_size):\n",
        "        \"\"\"\n",
        "        data_source: the souce pytorch dataset object\n",
        "        batch_size: the size of the chunks to keep together. Should generally be set to the desired batch size during training to minimize runtime. \n",
        "        \"\"\"\n",
        "        self.data_source = data_source\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "    def __iter__(self):\n",
        "        n = len(self.data_source)\n",
        "        \n",
        "        data = [x for x in range(n)]\n",
        "\n",
        "        # Create blocks\n",
        "        blocks = [data[i:i+self.batch_size] for i in range(0,len(data),self.batch_size)]\n",
        "        # shuffle the blocks\n",
        "        random.shuffle(blocks)\n",
        "        # concatenate the shuffled blocks\n",
        "        data[:] = [b for bs in blocks for b in bs]\n",
        "        \n",
        "        return iter(data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data_source)\n",
        "    \n",
        "#We want to hadnel true variable length\n",
        "#Data loader needs equal length. So use special function to padd all the data in a single batch to be of equal length\n",
        "#to the longest item in the batch\n",
        "def pad_collate_func(batch):\n",
        "    \"\"\"\n",
        "    This should be used as the collate_fn=pad_collate_func for a pytorch DataLoader object in order to pad out files in a batch to the length of the longest item in the batch. \n",
        "    \"\"\"\n",
        "    vecs = [x[0] for x in batch]\n",
        "    labels = [x[1] for x in batch]\n",
        "    \n",
        "    x = torch.nn.utils.rnn.pad_sequence(vecs, batch_first=True)\n",
        "    #stack will give us (B, 1), so index [:,0] to get to just (B)\n",
        "    y = torch.stack(labels)[:,0]\n",
        "    \n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "keeOqOm_24DU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11001\n"
          ]
        }
      ],
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_data = BinaryDataset(\"/Users/nando/OfflineStuff/BinaryMalware/train/benign_updated\", '/Users/nando/OfflineStuff/BinaryMalware/train/malware', sort_by_size=False, max_len=2000000)\n",
        "# train_loader = DataLoader(train_data, batch_size, collate_fn=pad_collate_func)\n",
        "m = len(train_data)\n",
        "print(m)\n",
        "train_data, val_data = random_split(train_data, [int(m-m*0.2+1), int(m*0.2)])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size, collate_fn=pad_collate_func)\n",
        "valid_loader = DataLoader(val_data, batch_size, collate_fn=pad_collate_func)\n",
        "\n",
        "\n",
        "\n",
        "test_data = BinaryDataset(\"/Users/nando/OfflineStuff/BinaryMalware/test/benign_updated\", '/Users/nando/OfflineStuff/BinaryMalware/test/malware', sort_by_size=False, max_len=2000000)\n",
        "test_loader = DataLoader(test_data, batch_size, collate_fn=pad_collate_func)\n",
        "\n",
        "# for a,b in train_loader:\n",
        "#   print(a[0].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv7PNzYXAxRf"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT3mPDFNBeTo"
      },
      "source": [
        "### LowMemConvBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peRD4oEP3RF3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def drop_zeros_hook(module, grad_input, grad_out):\n",
        "    \"\"\"\n",
        "    This function is used to replace gradients that are all zeros with None\n",
        "    In pyTorch None will not get back-propogated\n",
        "    So we use this as a approximation to saprse BP to avoid redundant and useless work\n",
        "    \"\"\"\n",
        "    grads = []\n",
        "    with torch.no_grad():\n",
        "        for g in grad_input:\n",
        "            if torch.nonzero(g).shape[0] == 0:\n",
        "                grads.append(g.to_sparse())\n",
        "            else:\n",
        "                grads.append(g)\n",
        "                \n",
        "    return tuple(grads)\n",
        "\n",
        "\n",
        "class CatMod(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CatMod, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat(x, dim=2)\n",
        "    \n",
        "    \n",
        "class LowMemConvBase(nn.Module):\n",
        "    \n",
        "    def __init__(self, chunk_size=65536, overlap=512, min_chunk_size=1024):\n",
        "        \"\"\"\n",
        "        chunk_size: how many bytes at a time to process. Increasing may improve compute efficent, but use more memory. Total memory use will be a function of chunk_size, and not of the length of the input sequence L\n",
        "        \n",
        "        overlap: how many bytes of overlap to use between chunks\n",
        "        \n",
        "        \"\"\"\n",
        "        super(LowMemConvBase, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "        self.min_chunk_size = min_chunk_size\n",
        "            \n",
        "        #Used for pooling over time in a more efficent way\n",
        "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.cat = CatMod()\n",
        "        self.cat.register_backward_hook(drop_zeros_hook)\n",
        "        self.receptive_field = None\n",
        "        \n",
        "        #Used to force checkpoint code to behave correctly due to poor design https://discuss.pytorch.org/t/checkpoint-with-no-grad-requiring-inputs-problem/19117/11\n",
        "        self.dummy_tensor = torch.ones(1, dtype=torch.float32, requires_grad=True)\n",
        "    \n",
        "    def processRange(self, x, **kwargs):\n",
        "        \"\"\"\n",
        "        This method does the work to convert an LongTensor input x of shape (B, L) , where B is the batch size and L is the length of the input. The output of this functoin should be a tensor of (B, C, L), where C is the number of channels, and L is again the input length (though its OK if it got a little shorter due to convs without padding or something). \n",
        "        \n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def determinRF(self):\n",
        "        \"\"\"\n",
        "        This function evaluates the receptive field & stride of our sub-network.\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.receptive_field is not None:\n",
        "            return self.receptive_field, self.stride, self.out_channels\n",
        "        \n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = \"cpu\"\n",
        "            \n",
        "        #Lets do a simple binary search to figure out how large our RF is. \n",
        "        #It can't be larger than our chunk size! So use that as upper bound\n",
        "        min_rf = 1\n",
        "        max_rf = self.chunk_size\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            \n",
        "            tmp = torch.zeros((1,max_rf)).long().to(cur_device)\n",
        "            \n",
        "            while True:\n",
        "                test_size = (min_rf+max_rf)//2\n",
        "                is_valid = True\n",
        "                try:\n",
        "                    self.processRange(tmp[:,0:test_size])\n",
        "                except:\n",
        "                    is_valid = False\n",
        "                \n",
        "                if is_valid:\n",
        "                    max_rf = test_size\n",
        "                else:\n",
        "                    min_rf = test_size+1\n",
        "                    \n",
        "                if max_rf == min_rf:\n",
        "                    self.receptive_field = min_rf\n",
        "                    out_shape = self.processRange(tmp).shape\n",
        "                    self.stride = self.chunk_size//out_shape[2]\n",
        "                    self.out_channels = out_shape[1]\n",
        "                    break\n",
        "                    \n",
        "                \n",
        "        return self.receptive_field, self.stride, self.out_channels\n",
        "                \n",
        "    \n",
        "    def pool_group(self, *args):\n",
        "        x = self.cat(args)\n",
        "        x = self.pooling(x)\n",
        "        return x\n",
        "    \n",
        "    def seq2fix(self, x, pr_args={}):\n",
        "        \"\"\"\n",
        "        Takes in an input LongTensor of (B, L) that will be converted to a fixed length representation (B, C), \n",
        "        where C is the number of channels provided by the base_network given at construction. \n",
        "        \"\"\"\n",
        "        \n",
        "        receptive_window, stride, out_channels = self.determinRF()\n",
        "        \n",
        "        if x.shape[1] < receptive_window: #This is a tiny input! Pad it out \n",
        "            x = F.pad(x, (0, receptive_window-x.shape[1]), value=0) # 0 is the pad value  \n",
        "        batch_size = x.shape[0]\n",
        "        length = x.shape[1]\n",
        "\n",
        "        #Let's go through the input data without gradients first, and find the positions that \"win\"\n",
        "        #the max-pooling. Most of the gradients will be zero, and we don't want to waste valuable\n",
        "        #memory and time computing them. \n",
        "        #Once we know the winners, we will go back and compute the forward activations on JUST\n",
        "        #the subset of positions that won!\n",
        "        winner_values = np.zeros((batch_size, out_channels))-1.0\n",
        "        winner_indices = np.zeros((batch_size, out_channels), dtype=np.int64)\n",
        "            \n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = None\n",
        "\n",
        "        step = self.chunk_size #- self.overlap\n",
        "        start = 0\n",
        "        end = start+step\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            while start < end and (end-start) >= max(self.min_chunk_size, receptive_window):\n",
        "                x_sub = x[:,start:end]\n",
        "                if cur_device is not None:\n",
        "                    x_sub = x_sub.to(cur_device)\n",
        "                activs = self.processRange(x_sub.long(), **pr_args)\n",
        "                activ_win, activ_indx = F.max_pool1d(activs, kernel_size=activs.shape[2], return_indices=True)\n",
        "                #We want to remove only last dimension, but if batch size is 1, np.squeeze\n",
        "                #will screw us up and remove first dim too.\n",
        "                #activ_win = np.squeeze(activ_win.cpu().numpy())\n",
        "                #activ_indx = np.squeeze(activ_indx.cpu().numpy())\n",
        "                activ_win = activ_win.cpu().numpy()[:,:,0]\n",
        "                activ_indx = activ_indx.cpu().numpy()[:,:,0]\n",
        "                selected = winner_values < activ_win\n",
        "                winner_indices[selected] = activ_indx[selected]*stride + start \n",
        "                winner_values[selected]  = activ_win[selected]\n",
        "                start = end\n",
        "                end = min(start+step, length)\n",
        "\n",
        "        # Now we know every index that won, we need to compute values and with gradients! \n",
        "\n",
        "        # Find unique winners for every batch\n",
        "        final_indices = [np.unique(winner_indices[b,:]) for b in range(batch_size)]\n",
        "        \n",
        "        # Collect inputs that won for each batch\n",
        "        chunk_list = [[x[b:b+1,max(i-receptive_window,0):min(i+receptive_window,length)] for i in final_indices[b]] for b in range(batch_size)]\n",
        "        # Convert to a torch tensor of the bytes\n",
        "        chunk_list = [torch.cat(c, dim=1)[0,:] for c in chunk_list]\n",
        "        \n",
        "        # Pad out shorter sequences to the longest one\n",
        "        x_selected = torch.nn.utils.rnn.pad_sequence(chunk_list, batch_first=True)\n",
        "        \n",
        "        # Shape is not (B, L). Compute it.     \n",
        "        if cur_device is not None:\n",
        "            x_selected = x_selected.to(cur_device)\n",
        "        x_selected = self.processRange(x_selected.long(), **pr_args)\n",
        "        x_selected = self.pooling(x_selected)\n",
        "        x_selected = x_selected.view(x_selected.size(0), -1)\n",
        "            \n",
        "        return x_selected\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6imfLaM3a1n"
      },
      "source": [
        "### AvastConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMb57dz83gG8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def vec_bin_array(arr, m=8):\n",
        "    \"\"\"\n",
        "    Arguments: \n",
        "    arr: Numpy array of positive integers\n",
        "    m: Number of bits of each integer to retain\n",
        "\n",
        "    Returns a copy of arr with every element replaced with a bit vector.\n",
        "    Bits encoded as int8's.\n",
        "    \"\"\"\n",
        "    to_str_func = np.vectorize(lambda x: np.binary_repr(x).zfill(m))\n",
        "    strs = to_str_func(arr)\n",
        "    ret = np.zeros(list(arr.shape) + [m], dtype=np.int8)\n",
        "    for bit_ix in range(0, m):\n",
        "        fetch_bit_func = np.vectorize(lambda x: x[bit_ix] == '1')\n",
        "        ret[...,bit_ix] = fetch_bit_func(strs).astype(np.int8)\n",
        "\n",
        "    return (ret*2-1).astype(np.float32)/16\n",
        "\n",
        "class AvastConv(LowMemConvBase):\n",
        "    \n",
        "    def __init__(self, out_size=2, channels=48, window_size=32, stride=4, embd_size=8):\n",
        "        super(AvastConv, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        for i in range(1, 257):\n",
        "            self.embd.weight.data[i,:] = torch.tensor(vec_bin_array(np.asarray([i])))\n",
        "        for param in self.embd.parameters():\n",
        "             param.requires_grad = False\n",
        "                 \n",
        "        self.conv_1 = nn.Conv1d(8, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(channels, channels*2, window_size, stride=stride, bias=True)\n",
        "        self.pool = nn.MaxPool1d(4)\n",
        "        self.conv_3 = nn.Conv1d(channels*2, channels*3, window_size//2, stride=stride*2, bias=True)\n",
        "        self.conv_4 = nn.Conv1d(channels*3, channels*4, window_size//2, stride=stride*2, bias=True)\n",
        "        \n",
        "        self.fc_1 = nn.Linear(channels*4, channels*4)\n",
        "        self.fc_2 = nn.Linear(channels*4, channels*3)\n",
        "        self.fc_3 = nn.Linear(channels*3, channels*2)\n",
        "        self.fc_4 = nn.Linear(channels*2, out_size)\n",
        "        \n",
        "    \n",
        "    def processRange(self, x):\n",
        "        # Fixed embedding\n",
        "        with torch.no_grad():\n",
        "            x = self.embd(x)\n",
        "            x = torch.transpose(x,-1,-2)\n",
        "         \n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv_3(x))\n",
        "        x = F.relu(self.conv_4(x))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "        \n",
        "        x = F.selu(self.fc_1(x))\n",
        "        x = F.selu(self.fc_2(x))\n",
        "        penult = x = F.selu(self.fc_3(x))\n",
        "        x = self.fc_4(x)\n",
        "        \n",
        "        return x, penult, post_conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2nX0Qku4NAS"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojJiIfdraJ3p",
        "outputId": "6e9066a2-c3f6-4cff-fc90-d23e63052769"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKQMjEa43jlB"
      },
      "outputs": [],
      "source": [
        "net = AvastConv()\n",
        "\n",
        "# If BCELoss is used instead of logit\n",
        "# channel_size = 48\n",
        "# net.fc_4 = nn.Sequential(\n",
        "#                nn.Linear(channel_size*2, 2),\n",
        "#                nn.Sigmoid())\n",
        "\n",
        "net.to(device)\n",
        "summary(net, (100,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41ijXAf4ZLYb"
      },
      "outputs": [],
      "source": [
        "# checkpoint = torch.load('logs/avastcnn.checkpoint', map_location=device)\n",
        "# try:\n",
        "#   net.load_state_dict(checkpoint['model_state_dict'])\n",
        "# except:\n",
        "#   print(\"No valid checkpoint data\")\n",
        "\n",
        "# del checkpoint['model_state_dict']\n",
        "# del checkpoint['optimizer_state_dict']\n",
        "# args_to_use = checkpoint\n",
        "\n",
        "lt = time.localtime()\n",
        "base_name = 'logs/log-' + str(lt[2])+'_v cc'+str(lt[1])+'-'+str(lt[3])+':'+str(lt[4])\n",
        "\n",
        "if not os.path.exists(base_name):\n",
        "    os.makedirs(base_name)\n",
        "file_name = os.path.join(base_name, base_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddYtik_Xn43G"
      },
      "outputs": [],
      "source": [
        "n_epochs = 20\n",
        "\n",
        "optimizer = optim.AdamW(net.parameters()) # AdamW has shown better generalization than Adam and on par with SGD and Momentum used in state of the art\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = StepLR(optimizer, step_size=n_epochs//10, gamma=0.5) # Decays the learning rate of each parameter group by gamma every step_size epochs.\n",
        "\n",
        "headers = ['epoch', 'train_acc','train_loss', 'val_acc'] # For csv printing\n",
        "\n",
        "with open(base_name + \".csv\", 'w') as csv_log_out:\n",
        "    csv_log_out.write(\",\".join(headers) + \"\\n\")\n",
        "\n",
        "    for epoch in (range(n_epochs)):\n",
        "        preds = []\n",
        "        truths = []\n",
        "        running_loss = 0.0\n",
        "        train_loss = []\n",
        "\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Dictionary used to store the values for the csv\n",
        "        epoch_stats = {'epoch':epoch} \n",
        "        \n",
        "        # Set model to train mode\n",
        "        net.train() \n",
        "\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "\n",
        "            ## Step 1: Load the data on the device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Keep inputs on CPU, the net will load chunks of input onto device as needed\n",
        "            # labels = labels.to(device)\n",
        "\n",
        "            ## Step 2: Run the model on the input data            \n",
        "            outputs, penult, post_conv = net(inputs)\n",
        "            # outputs, penultimate_activ, conv_active = net.forward_extra(inputs)\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss = loss #+ decov_lambda*(decov_penalty(penultimate_activ) + decov_penalty(conv_active))\n",
        "            #     loss = loss + decov_lambda*(decov_penalty(conv_active))\n",
        "            train_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds.extend(F.softmax(outputs, dim=-1).data[:,1].detach().cpu().numpy().ravel())\n",
        "                truths.extend(labels.detach().cpu().numpy().ravel())\n",
        "\n",
        "            \n",
        "\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        ## End Train Loop\n",
        "\n",
        "        print(\"Training Accuracy: {}\".format(train_correct*100.0/train_total))\n",
        "        print(\"Training Loss: {}\".format(np.mean(train_loss)))\n",
        "      \n",
        "        epoch_stats['train_acc'] = train_correct*1.0/train_total\n",
        "        epoch_stats['train_loss'] = np.mean(train_loss)\n",
        "\n",
        "        ## Save the net and current state!\n",
        "        net_path = os.path.join(base_name, \"epoch_{}.checkpoint\".format(epoch))\n",
        "\n",
        "        ## Test Set Eval\n",
        "        net.eval()\n",
        "        eval_train_correct = 0\n",
        "        eval_train_total = 0\n",
        "\n",
        "        preds = []\n",
        "        truths = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(valid_loader):\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs, _, _ = net(inputs)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                preds.extend(F.softmax(outputs, dim=-1).data[:,1].detach().cpu().numpy().ravel())\n",
        "                truths.extend(labels.detach().cpu().numpy().ravel())\n",
        "\n",
        "                eval_train_total += labels.size(0)\n",
        "                eval_train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(\"Val Accuracy: {}\".format(eval_train_correct*100.0/eval_train_total))\n",
        "\n",
        "        epoch_stats['val_acc'] = eval_train_correct*1.0/eval_train_total\n",
        "\n",
        "        csv_log_out.write(\",\".join([str(epoch_stats[h]) for h in headers]) + \"\\n\")\n",
        "        csv_log_out.flush()\n",
        "        \n",
        "        scheduler.step()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('ai4c')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2a8f56980c43ed3e97a1d3d88744694c9e75e1ca44ed28ab0a3ab4b4ff3b70eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
